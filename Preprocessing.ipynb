{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import glob\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import scenedetect\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PySceneDetect to establish shot boundaries\n",
    "def shot_detector(video_path, scene_path):\n",
    "    cmd = 'scenedetect --input %s detect-content --threshold %d list-scenes -o %s' % (video_path, 50, scene_path)\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning the subtitles with the shot boundaries\n",
    "def aligner(scenes, subs, noise):\n",
    "    recap = noise[0]\n",
    "    intro_starts = noise[1]\n",
    "    intro_ends = noise[2]\n",
    "    sneak = noise[3]\n",
    "    subs['SecondStart'] = subs['startTime'].apply(lambda x: to_seconds_converter(x))\n",
    "    subs['SecondEnd'] = subs['endTime'].apply(lambda x: to_seconds_converter(x))\n",
    "    columns = scenes.columns.tolist()\n",
    "    columns.append('text')\n",
    "    alignment_df = pd.DataFrame(columns=columns)\n",
    "    for index, row in scenes.iterrows():\n",
    "        new_line = row.values\n",
    "        start_frame = row['Start Frame']\n",
    "        end_frame = row['End Frame']\n",
    "        start_time = to_seconds_converter(row['Start Timecode'])\n",
    "        end_time = to_seconds_converter(row['End Timecode'])\n",
    "        if start_frame <= recap or (start_frame >= intro_starts and start_frame <= intro_ends) or \\\n",
    "        (end_frame >= intro_starts and end_frame <= intro_ends) or end_frame >= sneak:\n",
    "            sub_text = False\n",
    "        else:\n",
    "            # <= end_time\n",
    "            sub_result = subs.loc[(subs['SecondStart'] >= start_time) & (subs['SecondStart'] < end_time)]\n",
    "            if len(sub_result) > 1:\n",
    "                sub_text = ' '.join(sub_result['text'])\n",
    "            elif len(sub_result) == 0:\n",
    "                sub_text = False\n",
    "            else:\n",
    "                if not sub_result['text'].to_string().isupper():\n",
    "                    sub_text = sub_result['text']\n",
    "                else:\n",
    "                    sub_text = False\n",
    "        \n",
    "        new_line = np.append(new_line, sub_text)\n",
    "        alignment_df.loc[index] = new_line\n",
    "    return alignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the subtitle data\n",
    "def preprocess_text(text):\n",
    "    new_text = a.sub('\\\\1\\\\2 ', text)\n",
    "    new_text = b.sub('ok', new_text)\n",
    "    new_text = c.sub(' ', new_text)\n",
    "    final_text = [word for word in new_text.split(' ') if not word[:2].isupper()]\n",
    "    if len(final_text) < 2:\n",
    "        return 'False'\n",
    "    return ' '.join(final_text).strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to detect recaps, intro song, and sneak peeks in the video data. \n",
    "# The shots that fall into the time stamps that are associated with these three parts of the episode are excluded.\n",
    "def recap_intro_sneak(subs, video_path):\n",
    "    gold_recap = cv2.imread('gold/recap.jpg')\n",
    "    gold_intro = cv2.imread('gold/intro.jpg')\n",
    "    gold_sneakpeek = cv2.imread('gold/sneakpeek.jpg')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(5)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = cap.read()\n",
    "        frameId = int(cap.get(1))\n",
    "        current_time = cap.get(0)\n",
    "        \n",
    "        #current_time <= 32000; 64000\n",
    "        #if current_time >= 28000 and current_time <= 64000:\n",
    "        if current_time >= 28000 and current_time <= 124000:\n",
    "            if frameId % 13 == 0:\n",
    "            #if frameId % 6 == 0:\n",
    "                if mse(frame, gold_recap):\n",
    "                    recap_stops = frameId\n",
    "                    #print(frameId)\n",
    "        \n",
    "        intro_start = duration_converter(subs[subs['text'].str.startswith('*de tijd')].values[0][2])\n",
    "        \n",
    "        if current_time == intro_start:\n",
    "            intro_id = frameId\n",
    "        \n",
    "        if current_time >= intro_start + 28000 and current_time <= intro_start + 32000:\n",
    "            if frameId % 5 == 0:\n",
    "                if mse(frame, gold_intro):\n",
    "                    intro_stop = frameId\n",
    "                    #print(frameId)\n",
    "        \n",
    "        if current_time >= 1200000:\n",
    "            if frameId % 5 == 0:\n",
    "                if frame is not None:\n",
    "                    if mse(frame, gold_sneakpeek):\n",
    "                        sneakpeek_start = frameId \n",
    "    cap.release()\n",
    "    return (recap_stops, intro_id - 25, intro_stop, sneakpeek_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MSE function to calculate the similarity between prototypical recap, sneak peed, intro song frames \n",
    "#and the current frame\n",
    "def mse(imageA, imageB): \n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    imageA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "    imageB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    \n",
    "    if err >= 0 and err < 550:\n",
    "        return True\n",
    "    return False \n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    # return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining it all together: path_video - is the path to our mp4 GTST files, path_subtitles - the path to the subtitles\n",
    "# path_scenes and path_aligner - are folders for the metadata to be saved to.\n",
    "def main_preprocessor(path_video, path_subtitles, path_scenes, path_aligner):\n",
    "    \n",
    "    for filepath in glob.iglob('%s/*.mp4' % path_video):\n",
    "        episode_id = filepath.split('/')[-1].split('_')[0]\n",
    "        video_name = filepath.split('/')[-1][:-4]\n",
    "        if episode_id not in filtering:\n",
    "            scene_path = os.path.join(path_scenes, episode_id)\n",
    "            print('starting shot detection')\n",
    "            scenes = shot_detector(filepath, scene_path)\n",
    "            subtitles = pd.read_csv('%s/gtst_episodes_5491_5710.csv' % path_subtitles, header=0, sep=';')\n",
    "            replaced_id = episode_id[:-1] + 'T'\n",
    "            episode_subs = subtitles.loc[subtitles['tapeId']  == replaced_id]\n",
    "            list_scenes_path = '%s/%s-Scenes.csv' % (scene_path, video_name)\n",
    "            print(list_scenes_path)\n",
    "            list_scenes = pd.read_csv(list_scenes_path, header=1, sep=',')\n",
    "            print('starting noise detection')\n",
    "            noise = recap_intro_sneak(episode_subs, filepath)\n",
    "            print('starting alignment')\n",
    "            aligned_df = aligner(list_scenes, episode_subs, noise)\n",
    "            aligned_df.to_csv('%s/%s.csv' % (path_aligner, episode_id))\n",
    "            print('the episode is complete')\n",
    "    return 'the job is done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_preprocessor('video', 'subs', 'list_scenes', 'alignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the log data containing the information about start/end points of the shots and the cleaned subtitle.\n",
    "# For every shot of the GTST season. This log file is called 'cleaned_subs_log.csv' in our repository\n",
    "def concatination():\n",
    "    subtitles = pd.read_csv('subs/gtst_episodes_5491_5710.csv', header=0, sep=';')\n",
    "    video_path = '/Volumes/2TB'\n",
    "    alignment_path = 'alignment'\n",
    "    columns = new_test.columns.tolist()\n",
    "    columns.append('episode_nr')\n",
    "    columns.append('video_path')\n",
    "    resulting_df = pd.DataFrame(columns=columns)\n",
    "    for filepath in glob.iglob('%s/*.mp4' % video_path):\n",
    "        episode_id = filepath.split('/')[-1].split('_')[0]\n",
    "        video_name = filepath.split('/')[-1]\n",
    "        replaced_id = episode_id[:-1] + 'T'\n",
    "        s = subtitles.loc[subtitles['tapeId']  == replaced_id]\n",
    "        episode_nr = s['episode_nr']\n",
    "        if episode_id != '248108H1' and episode_id != '248139H1':\n",
    "            aligned_df = pd.read_csv('%s/%s.csv' % (alignment_path, episode_id), index_col=0, header=0)\n",
    "            aligned_df['tapeId'] = episode_id\n",
    "            aligned_df['episode_nr'] = episode_nr.unique()[0]\n",
    "            aligned_df['video_path'] = filepath\n",
    "            resulting_df = pd.concat([resulting_df, aligned_df], ignore_index=True, sort=False)\n",
    "    return resulting_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = concatination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['index'] = result.index\n",
    "result.to_csv('log_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene Number</th>\n",
       "      <th>Start Frame</th>\n",
       "      <th>Start Timecode</th>\n",
       "      <th>Start Time (seconds)</th>\n",
       "      <th>End Frame</th>\n",
       "      <th>End Timecode</th>\n",
       "      <th>End Time (seconds)</th>\n",
       "      <th>Length (frames)</th>\n",
       "      <th>Length (timecode)</th>\n",
       "      <th>Length (seconds)</th>\n",
       "      <th>text</th>\n",
       "      <th>tapeId</th>\n",
       "      <th>episode_nr</th>\n",
       "      <th>video_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>184</td>\n",
       "      <td>00:00:07.360</td>\n",
       "      <td>7.36</td>\n",
       "      <td>184</td>\n",
       "      <td>00:00:07.360</td>\n",
       "      <td>7.36</td>\n",
       "      <td>False</td>\n",
       "      <td>241919H1</td>\n",
       "      <td>5491</td>\n",
       "      <td>/Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "      <td>00:00:07.360</td>\n",
       "      <td>7.36</td>\n",
       "      <td>221</td>\n",
       "      <td>00:00:08.840</td>\n",
       "      <td>8.84</td>\n",
       "      <td>37</td>\n",
       "      <td>00:00:01.480</td>\n",
       "      <td>1.48</td>\n",
       "      <td>False</td>\n",
       "      <td>241919H1</td>\n",
       "      <td>5491</td>\n",
       "      <td>/Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>221</td>\n",
       "      <td>00:00:08.840</td>\n",
       "      <td>8.84</td>\n",
       "      <td>320</td>\n",
       "      <td>00:00:12.800</td>\n",
       "      <td>12.80</td>\n",
       "      <td>99</td>\n",
       "      <td>00:00:03.960</td>\n",
       "      <td>3.96</td>\n",
       "      <td>False</td>\n",
       "      <td>241919H1</td>\n",
       "      <td>5491</td>\n",
       "      <td>/Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "      <td>00:00:12.800</td>\n",
       "      <td>12.80</td>\n",
       "      <td>363</td>\n",
       "      <td>00:00:14.520</td>\n",
       "      <td>14.52</td>\n",
       "      <td>43</td>\n",
       "      <td>00:00:01.720</td>\n",
       "      <td>1.72</td>\n",
       "      <td>False</td>\n",
       "      <td>241919H1</td>\n",
       "      <td>5491</td>\n",
       "      <td>/Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>363</td>\n",
       "      <td>00:00:14.520</td>\n",
       "      <td>14.52</td>\n",
       "      <td>434</td>\n",
       "      <td>00:00:17.360</td>\n",
       "      <td>17.36</td>\n",
       "      <td>71</td>\n",
       "      <td>00:00:02.840</td>\n",
       "      <td>2.84</td>\n",
       "      <td>False</td>\n",
       "      <td>241919H1</td>\n",
       "      <td>5491</td>\n",
       "      <td>/Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scene Number Start Frame Start Timecode  Start Time (seconds) End Frame  \\\n",
       "0            1           0   00:00:00.000                  0.00       184   \n",
       "1            2         184   00:00:07.360                  7.36       221   \n",
       "2            3         221   00:00:08.840                  8.84       320   \n",
       "3            4         320   00:00:12.800                 12.80       363   \n",
       "4            5         363   00:00:14.520                 14.52       434   \n",
       "\n",
       "   End Timecode  End Time (seconds) Length (frames) Length (timecode)  \\\n",
       "0  00:00:07.360                7.36             184      00:00:07.360   \n",
       "1  00:00:08.840                8.84              37      00:00:01.480   \n",
       "2  00:00:12.800               12.80              99      00:00:03.960   \n",
       "3  00:00:14.520               14.52              43      00:00:01.720   \n",
       "4  00:00:17.360               17.36              71      00:00:02.840   \n",
       "\n",
       "   Length (seconds)   text    tapeId episode_nr  \\\n",
       "0              7.36  False  241919H1       5491   \n",
       "1              1.48  False  241919H1       5491   \n",
       "2              3.96  False  241919H1       5491   \n",
       "3              1.72  False  241919H1       5491   \n",
       "4              2.84  False  241919H1       5491   \n",
       "\n",
       "                                          video_path  \n",
       "0  /Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...  \n",
       "1  /Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...  \n",
       "2  /Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...  \n",
       "3  /Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...  \n",
       "4  /Volumes/2TB/241919H1_Goede_Tijden_Slechte_Tij...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the whole episode files into shots according to the log file\n",
    "def shot_cutter():\n",
    "    log_df = pd.read_csv('log_data.csv', header=0)\n",
    "    write_path = '/Volumes/Personal/shots'\n",
    "    for index, row in log_df.iterrows():\n",
    "        if row['text'] != 'False' and str(row['index']) not in filtering:\n",
    "            cmd = 'ffmpeg -i %s -c copy -ss %s -to %s %s/%d.mp4' % (row['video_path'], row['Start Timecode'], row['End Timecode'], \n",
    "                                                                           write_path, row['index'])\n",
    "            !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some time converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ms\n",
    "def duration_converter(time_string):\n",
    "    hms = str(time_string).split(':')\n",
    "    m = int(hms[1])\n",
    "    s = int(hms[2].split('.')[0])\n",
    "    ms = int(hms[2].split('.')[1])\n",
    "    return m * 60000 + s * 1000 + ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds_converter(time_string):\n",
    "    hms = str(time_string).split(':')\n",
    "    m = int(hms[1])\n",
    "    s = int(hms[2].split('.')[0])\n",
    "    # ms = int(hms[2].split('.')[1])\n",
    "    return m * 60 + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ms to mm:ss.fff\n",
    "def duration_to_string(ms):\n",
    "    last = ms % 1000\n",
    "    seconds = (ms // 1000) % 60\n",
    "    minutes = (ms // 1000) // 60\n",
    "    return '%d:%d.%d' % (minutes, seconds, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('new_log.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mute the audio cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'shots/*.mp4'\n",
    "for video in glob.iglob(video_path):\n",
    "    video_index = int(video.split('/')[-1].split('.')[0])\n",
    "    if video_index <= 8561:\n",
    "        new_path = 'muted/%d.mp4'% video_index\n",
    "        mute_audio(video, new_path)\n",
    "        print(video_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mute_audio(video_path, new_path):\n",
    "    cmd = 'ffmpeg -i %s -an -vcodec copy %s' % (video_path, new_path)\n",
    "    !{cmd}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
